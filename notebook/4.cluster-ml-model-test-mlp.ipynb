{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning : Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# gradient boosting for regression in scikit-learn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "#from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from lightgbm import LGBMClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data and set the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "import pickle\n",
    " \n",
    "X, y = pickle.load( open( \"cluster-mldata.plk\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4442, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4442,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the traing and test set\n",
    "X_train, X_test, y_train0, y_test0 = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train0, num_classes=2)\n",
    "y_test  = to_categorical(y_test0, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: MLP\n",
    "# Simple Fit using the whole train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model \n",
    "model = Sequential()\n",
    "model.add(Dense(30,input_dim=2,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "#Compile and Fit the model\n",
    "#model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3109 samples, validate on 1333 samples\n",
      "Epoch 1/200\n",
      "3109/3109 [==============================] - 0s 51us/step - loss: 0.6938 - accuracy: 0.5172 - val_loss: 0.6869 - val_accuracy: 0.6302\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68689, saving model to ./model/01-0.6869.hdf5\n",
      "Epoch 2/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.6845 - accuracy: 0.6250 - val_loss: 0.6779 - val_accuracy: 0.6414\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68689 to 0.67792, saving model to ./model/02-0.6779.hdf5\n",
      "Epoch 3/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.6754 - accuracy: 0.6385 - val_loss: 0.6692 - val_accuracy: 0.6474\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67792 to 0.66917, saving model to ./model/03-0.6692.hdf5\n",
      "Epoch 4/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.6660 - accuracy: 0.6587 - val_loss: 0.6598 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66917 to 0.65977, saving model to ./model/04-0.6598.hdf5\n",
      "Epoch 5/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.6549 - accuracy: 0.6806 - val_loss: 0.6477 - val_accuracy: 0.6797\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65977 to 0.64767, saving model to ./model/05-0.6477.hdf5\n",
      "Epoch 6/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.6409 - accuracy: 0.7028 - val_loss: 0.6315 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64767 to 0.63151, saving model to ./model/06-0.6315.hdf5\n",
      "Epoch 7/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.6205 - accuracy: 0.7285 - val_loss: 0.6076 - val_accuracy: 0.7299\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.63151 to 0.60761, saving model to ./model/07-0.6076.hdf5\n",
      "Epoch 8/200\n",
      "3109/3109 [==============================] - 0s 8us/step - loss: 0.5957 - accuracy: 0.7173 - val_loss: 0.5820 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.60761 to 0.58201, saving model to ./model/08-0.5820.hdf5\n",
      "Epoch 9/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5725 - accuracy: 0.7198 - val_loss: 0.5626 - val_accuracy: 0.7247\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58201 to 0.56256, saving model to ./model/09-0.5626.hdf5\n",
      "Epoch 10/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5573 - accuracy: 0.7211 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56256 to 0.55109, saving model to ./model/10-0.5511.hdf5\n",
      "Epoch 11/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5474 - accuracy: 0.7237 - val_loss: 0.5439 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.55109 to 0.54392, saving model to ./model/11-0.5439.hdf5\n",
      "Epoch 12/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5412 - accuracy: 0.7282 - val_loss: 0.5402 - val_accuracy: 0.7329\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.54392 to 0.54016, saving model to ./model/12-0.5402.hdf5\n",
      "Epoch 13/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5375 - accuracy: 0.7298 - val_loss: 0.5367 - val_accuracy: 0.7374\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.54016 to 0.53671, saving model to ./model/13-0.5367.hdf5\n",
      "Epoch 14/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5350 - accuracy: 0.7298 - val_loss: 0.5350 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53671 to 0.53504, saving model to ./model/14-0.5350.hdf5\n",
      "Epoch 15/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5330 - accuracy: 0.7276 - val_loss: 0.5331 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53504 to 0.53306, saving model to ./model/15-0.5331.hdf5\n",
      "Epoch 16/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5313 - accuracy: 0.7350 - val_loss: 0.5326 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.53306 to 0.53265, saving model to ./model/16-0.5326.hdf5\n",
      "Epoch 17/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5305 - accuracy: 0.7353 - val_loss: 0.5308 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.53265 to 0.53076, saving model to ./model/17-0.5308.hdf5\n",
      "Epoch 18/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5294 - accuracy: 0.7362 - val_loss: 0.5311 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.53076\n",
      "Epoch 19/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5284 - accuracy: 0.7362 - val_loss: 0.5305 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53076 to 0.53050, saving model to ./model/19-0.5305.hdf5\n",
      "Epoch 20/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5280 - accuracy: 0.7356 - val_loss: 0.5286 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.53050 to 0.52861, saving model to ./model/20-0.5286.hdf5\n",
      "Epoch 21/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5272 - accuracy: 0.7353 - val_loss: 0.5293 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.52861\n",
      "Epoch 22/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5264 - accuracy: 0.7391 - val_loss: 0.5286 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.52861 to 0.52861, saving model to ./model/22-0.5286.hdf5\n",
      "Epoch 23/200\n",
      "3109/3109 [==============================] - 0s 7us/step - loss: 0.5258 - accuracy: 0.7401 - val_loss: 0.5272 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.52861 to 0.52721, saving model to ./model/23-0.5272.hdf5\n",
      "Epoch 24/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5255 - accuracy: 0.7404 - val_loss: 0.5266 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.52721 to 0.52657, saving model to ./model/24-0.5266.hdf5\n",
      "Epoch 25/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5252 - accuracy: 0.7404 - val_loss: 0.5281 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.52657\n",
      "Epoch 26/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5244 - accuracy: 0.7404 - val_loss: 0.5262 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.52657 to 0.52619, saving model to ./model/26-0.5262.hdf5\n",
      "Epoch 27/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5240 - accuracy: 0.7414 - val_loss: 0.5260 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.52619 to 0.52596, saving model to ./model/27-0.5260.hdf5\n",
      "Epoch 28/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5240 - accuracy: 0.7408 - val_loss: 0.5265 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.52596\n",
      "Epoch 29/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5231 - accuracy: 0.7411 - val_loss: 0.5261 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.52596\n",
      "Epoch 30/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5229 - accuracy: 0.7430 - val_loss: 0.5245 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.52596 to 0.52451, saving model to ./model/30-0.5245.hdf5\n",
      "Epoch 31/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5230 - accuracy: 0.7398 - val_loss: 0.5247 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.52451\n",
      "Epoch 32/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5221 - accuracy: 0.7401 - val_loss: 0.5247 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.52451\n",
      "Epoch 33/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5224 - accuracy: 0.7414 - val_loss: 0.5240 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.52451 to 0.52403, saving model to ./model/33-0.5240.hdf5\n",
      "Epoch 34/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5218 - accuracy: 0.7414 - val_loss: 0.5235 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.52403 to 0.52349, saving model to ./model/34-0.5235.hdf5\n",
      "Epoch 35/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5213 - accuracy: 0.7417 - val_loss: 0.5240 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.52349\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5212 - accuracy: 0.7420 - val_loss: 0.5241 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.52349\n",
      "Epoch 37/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5210 - accuracy: 0.7411 - val_loss: 0.5229 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.52349 to 0.52290, saving model to ./model/37-0.5229.hdf5\n",
      "Epoch 38/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5209 - accuracy: 0.7404 - val_loss: 0.5222 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.52290 to 0.52221, saving model to ./model/38-0.5222.hdf5\n",
      "Epoch 39/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5207 - accuracy: 0.7411 - val_loss: 0.5225 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.52221\n",
      "Epoch 40/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5206 - accuracy: 0.7411 - val_loss: 0.5225 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.52221\n",
      "Epoch 41/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5202 - accuracy: 0.7404 - val_loss: 0.5221 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.52221 to 0.52215, saving model to ./model/41-0.5221.hdf5\n",
      "Epoch 42/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5205 - accuracy: 0.7398 - val_loss: 0.5222 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.52215\n",
      "Epoch 43/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5199 - accuracy: 0.7414 - val_loss: 0.5216 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.52215 to 0.52159, saving model to ./model/43-0.5216.hdf5\n",
      "Epoch 44/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5197 - accuracy: 0.7408 - val_loss: 0.5215 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.52159 to 0.52153, saving model to ./model/44-0.5215.hdf5\n",
      "Epoch 45/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5195 - accuracy: 0.7414 - val_loss: 0.5219 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.52153\n",
      "Epoch 46/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5195 - accuracy: 0.7408 - val_loss: 0.5213 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.52153 to 0.52131, saving model to ./model/46-0.5213.hdf5\n",
      "Epoch 47/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5195 - accuracy: 0.7411 - val_loss: 0.5209 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.52131 to 0.52094, saving model to ./model/47-0.5209.hdf5\n",
      "Epoch 48/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5196 - accuracy: 0.7411 - val_loss: 0.5211 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.52094\n",
      "Epoch 49/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5191 - accuracy: 0.7417 - val_loss: 0.5217 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.52094\n",
      "Epoch 50/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5192 - accuracy: 0.7408 - val_loss: 0.5209 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.52094 to 0.52089, saving model to ./model/50-0.5209.hdf5\n",
      "Epoch 51/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5190 - accuracy: 0.7398 - val_loss: 0.5208 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.52089 to 0.52083, saving model to ./model/51-0.5208.hdf5\n",
      "Epoch 52/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5189 - accuracy: 0.7404 - val_loss: 0.5206 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.52083 to 0.52058, saving model to ./model/52-0.5206.hdf5\n",
      "Epoch 53/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5187 - accuracy: 0.7417 - val_loss: 0.5200 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.52058 to 0.52000, saving model to ./model/53-0.5200.hdf5\n",
      "Epoch 54/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5187 - accuracy: 0.7411 - val_loss: 0.5206 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.52000\n",
      "Epoch 55/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5186 - accuracy: 0.7420 - val_loss: 0.5207 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.52000\n",
      "Epoch 56/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5183 - accuracy: 0.7417 - val_loss: 0.5200 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.52000\n",
      "Epoch 57/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5187 - accuracy: 0.7395 - val_loss: 0.5204 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.52000\n",
      "Epoch 58/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5181 - accuracy: 0.7408 - val_loss: 0.5198 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.52000 to 0.51977, saving model to ./model/58-0.5198.hdf5\n",
      "Epoch 59/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5183 - accuracy: 0.7408 - val_loss: 0.5195 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.51977 to 0.51949, saving model to ./model/59-0.5195.hdf5\n",
      "Epoch 60/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5181 - accuracy: 0.7417 - val_loss: 0.5195 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.51949\n",
      "Epoch 61/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5182 - accuracy: 0.7424 - val_loss: 0.5197 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.51949\n",
      "Epoch 62/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5179 - accuracy: 0.7414 - val_loss: 0.5197 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.51949\n",
      "Epoch 63/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5180 - accuracy: 0.7411 - val_loss: 0.5201 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.51949\n",
      "Epoch 64/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5182 - accuracy: 0.7424 - val_loss: 0.5202 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.51949\n",
      "Epoch 65/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5177 - accuracy: 0.7408 - val_loss: 0.5197 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.51949\n",
      "Epoch 66/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5176 - accuracy: 0.7424 - val_loss: 0.5193 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.51949 to 0.51927, saving model to ./model/66-0.5193.hdf5\n",
      "Epoch 67/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5176 - accuracy: 0.7420 - val_loss: 0.5198 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.51927\n",
      "Epoch 68/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5177 - accuracy: 0.7420 - val_loss: 0.5197 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.51927\n",
      "Epoch 69/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5176 - accuracy: 0.7424 - val_loss: 0.5190 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.51927 to 0.51903, saving model to ./model/69-0.5190.hdf5\n",
      "Epoch 70/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5174 - accuracy: 0.7404 - val_loss: 0.5192 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.51903\n",
      "Epoch 71/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5172 - accuracy: 0.7424 - val_loss: 0.5194 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.51903\n",
      "Epoch 72/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5174 - accuracy: 0.7436 - val_loss: 0.5196 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.51903\n",
      "Epoch 73/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5175 - accuracy: 0.7395 - val_loss: 0.5185 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.51903 to 0.51852, saving model to ./model/73-0.5185.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5171 - accuracy: 0.7414 - val_loss: 0.5193 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.51852\n",
      "Epoch 75/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5169 - accuracy: 0.7417 - val_loss: 0.5183 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.51852 to 0.51832, saving model to ./model/75-0.5183.hdf5\n",
      "Epoch 76/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5171 - accuracy: 0.7427 - val_loss: 0.5184 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.51832\n",
      "Epoch 77/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5168 - accuracy: 0.7433 - val_loss: 0.5188 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.51832\n",
      "Epoch 78/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5172 - accuracy: 0.7401 - val_loss: 0.5193 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.51832\n",
      "Epoch 79/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5164 - accuracy: 0.7430 - val_loss: 0.5186 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.51832\n",
      "Epoch 80/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5169 - accuracy: 0.7443 - val_loss: 0.5185 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.51832\n",
      "Epoch 81/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5166 - accuracy: 0.7417 - val_loss: 0.5186 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.51832\n",
      "Epoch 82/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5170 - accuracy: 0.7414 - val_loss: 0.5188 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.51832\n",
      "Epoch 83/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5167 - accuracy: 0.7404 - val_loss: 0.5180 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.51832 to 0.51803, saving model to ./model/83-0.5180.hdf5\n",
      "Epoch 84/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5165 - accuracy: 0.7420 - val_loss: 0.5185 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.51803\n",
      "Epoch 85/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5165 - accuracy: 0.7401 - val_loss: 0.5191 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.51803\n",
      "Epoch 86/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5167 - accuracy: 0.7420 - val_loss: 0.5181 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.51803\n",
      "Epoch 87/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5169 - accuracy: 0.7385 - val_loss: 0.5190 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.51803\n",
      "Epoch 88/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5160 - accuracy: 0.7417 - val_loss: 0.5181 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.51803\n",
      "Epoch 89/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5160 - accuracy: 0.7420 - val_loss: 0.5180 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.51803 to 0.51795, saving model to ./model/89-0.5180.hdf5\n",
      "Epoch 90/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5167 - accuracy: 0.7391 - val_loss: 0.5187 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.51795\n",
      "Epoch 91/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5158 - accuracy: 0.7398 - val_loss: 0.5175 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.51795 to 0.51749, saving model to ./model/91-0.5175.hdf5\n",
      "Epoch 92/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5163 - accuracy: 0.7414 - val_loss: 0.5177 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.51749\n",
      "Epoch 93/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5163 - accuracy: 0.7395 - val_loss: 0.5194 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.51749\n",
      "Epoch 94/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5158 - accuracy: 0.7411 - val_loss: 0.5176 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.51749\n",
      "Epoch 95/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5158 - accuracy: 0.7411 - val_loss: 0.5170 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.51749 to 0.51700, saving model to ./model/95-0.5170.hdf5\n",
      "Epoch 96/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5155 - accuracy: 0.7411 - val_loss: 0.5174 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.51700\n",
      "Epoch 97/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.5181 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.51700\n",
      "Epoch 98/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5156 - accuracy: 0.7404 - val_loss: 0.5179 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.51700\n",
      "Epoch 99/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5158 - accuracy: 0.7401 - val_loss: 0.5180 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.51700\n",
      "Epoch 100/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5155 - accuracy: 0.7408 - val_loss: 0.5172 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.51700\n",
      "Epoch 101/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5153 - accuracy: 0.7417 - val_loss: 0.5174 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.51700\n",
      "Epoch 102/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5153 - accuracy: 0.7404 - val_loss: 0.5167 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.51700 to 0.51668, saving model to ./model/102-0.5167.hdf5\n",
      "Epoch 103/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5152 - accuracy: 0.7417 - val_loss: 0.5168 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.51668\n",
      "Epoch 104/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5149 - accuracy: 0.7408 - val_loss: 0.5167 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.51668 to 0.51665, saving model to ./model/104-0.5167.hdf5\n",
      "Epoch 105/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5154 - accuracy: 0.7404 - val_loss: 0.5169 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.51665\n",
      "Epoch 106/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5152 - accuracy: 0.7411 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.51665 to 0.51615, saving model to ./model/106-0.5161.hdf5\n",
      "Epoch 107/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5151 - accuracy: 0.7420 - val_loss: 0.5162 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.51615\n",
      "Epoch 108/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5149 - accuracy: 0.7401 - val_loss: 0.5170 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.51615\n",
      "Epoch 109/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5157 - accuracy: 0.7388 - val_loss: 0.5166 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.51615\n",
      "Epoch 110/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5160 - accuracy: 0.7408 - val_loss: 0.5161 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.51615 to 0.51614, saving model to ./model/110-0.5161.hdf5\n",
      "Epoch 111/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5148 - accuracy: 0.7433 - val_loss: 0.5170 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.51614\n",
      "Epoch 112/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5149 - accuracy: 0.7391 - val_loss: 0.5162 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.51614\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5146 - accuracy: 0.7398 - val_loss: 0.5161 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.51614 to 0.51608, saving model to ./model/113-0.5161.hdf5\n",
      "Epoch 114/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5146 - accuracy: 0.7414 - val_loss: 0.5160 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.51608 to 0.51599, saving model to ./model/114-0.5160.hdf5\n",
      "Epoch 115/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5142 - accuracy: 0.7414 - val_loss: 0.5158 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.51599 to 0.51575, saving model to ./model/115-0.5158.hdf5\n",
      "Epoch 116/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5146 - accuracy: 0.7401 - val_loss: 0.5156 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.51575 to 0.51562, saving model to ./model/116-0.5156.hdf5\n",
      "Epoch 117/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5149 - accuracy: 0.7414 - val_loss: 0.5157 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.51562\n",
      "Epoch 118/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5142 - accuracy: 0.7430 - val_loss: 0.5163 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.51562\n",
      "Epoch 119/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5142 - accuracy: 0.7411 - val_loss: 0.5158 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.51562\n",
      "Epoch 120/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5142 - accuracy: 0.7420 - val_loss: 0.5156 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.51562 to 0.51556, saving model to ./model/120-0.5156.hdf5\n",
      "Epoch 121/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5139 - accuracy: 0.7417 - val_loss: 0.5156 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.51556\n",
      "Epoch 122/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5138 - accuracy: 0.7436 - val_loss: 0.5151 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.51556 to 0.51512, saving model to ./model/122-0.5151.hdf5\n",
      "Epoch 123/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5139 - accuracy: 0.7420 - val_loss: 0.5153 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.51512\n",
      "Epoch 124/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5140 - accuracy: 0.7417 - val_loss: 0.5157 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.51512\n",
      "Epoch 125/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5137 - accuracy: 0.7411 - val_loss: 0.5149 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.51512 to 0.51487, saving model to ./model/125-0.5149.hdf5\n",
      "Epoch 126/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5138 - accuracy: 0.7404 - val_loss: 0.5150 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.51487\n",
      "Epoch 127/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5137 - accuracy: 0.7408 - val_loss: 0.5160 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.51487\n",
      "Epoch 128/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5135 - accuracy: 0.7411 - val_loss: 0.5152 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.51487\n",
      "Epoch 129/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5134 - accuracy: 0.7427 - val_loss: 0.5150 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.51487\n",
      "Epoch 130/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5134 - accuracy: 0.7398 - val_loss: 0.5159 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.51487\n",
      "Epoch 131/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5135 - accuracy: 0.7414 - val_loss: 0.5150 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.51487\n",
      "Epoch 132/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5139 - accuracy: 0.7430 - val_loss: 0.5147 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.51487 to 0.51467, saving model to ./model/132-0.5147.hdf5\n",
      "Epoch 133/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5135 - accuracy: 0.7427 - val_loss: 0.5156 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.51467\n",
      "Epoch 134/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5133 - accuracy: 0.7427 - val_loss: 0.5142 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.51467 to 0.51416, saving model to ./model/134-0.5142.hdf5\n",
      "Epoch 135/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5135 - accuracy: 0.7424 - val_loss: 0.5148 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.51416\n",
      "Epoch 136/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5146 - accuracy: 0.7420 - val_loss: 0.5161 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.51416\n",
      "Epoch 137/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5141 - accuracy: 0.7417 - val_loss: 0.5141 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.51416 to 0.51412, saving model to ./model/137-0.5141.hdf5\n",
      "Epoch 138/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5138 - accuracy: 0.7414 - val_loss: 0.5155 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.51412\n",
      "Epoch 139/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5129 - accuracy: 0.7420 - val_loss: 0.5142 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.51412\n",
      "Epoch 140/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5141 - accuracy: 0.7391 - val_loss: 0.5143 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.51412\n",
      "Epoch 141/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5131 - accuracy: 0.7430 - val_loss: 0.5151 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.51412\n",
      "Epoch 142/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5129 - accuracy: 0.7436 - val_loss: 0.5146 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.51412\n",
      "Epoch 143/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5126 - accuracy: 0.7427 - val_loss: 0.5145 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.51412\n",
      "Epoch 144/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5128 - accuracy: 0.7411 - val_loss: 0.5148 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.51412\n",
      "Epoch 145/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5129 - accuracy: 0.7417 - val_loss: 0.5145 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.51412\n",
      "Epoch 146/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5128 - accuracy: 0.7443 - val_loss: 0.5137 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.51412 to 0.51370, saving model to ./model/146-0.5137.hdf5\n",
      "Epoch 147/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5123 - accuracy: 0.7433 - val_loss: 0.5144 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.51370\n",
      "Epoch 148/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5126 - accuracy: 0.7427 - val_loss: 0.5142 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.51370\n",
      "Epoch 149/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5129 - accuracy: 0.7417 - val_loss: 0.5141 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.51370\n",
      "Epoch 150/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5131 - accuracy: 0.7401 - val_loss: 0.5151 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.51370\n",
      "Epoch 151/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5130 - accuracy: 0.7411 - val_loss: 0.5143 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.51370\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5128 - accuracy: 0.7411 - val_loss: 0.5144 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.51370\n",
      "Epoch 153/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5125 - accuracy: 0.7424 - val_loss: 0.5135 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.51370 to 0.51354, saving model to ./model/153-0.5135.hdf5\n",
      "Epoch 154/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5124 - accuracy: 0.7462 - val_loss: 0.5141 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.51354\n",
      "Epoch 155/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5118 - accuracy: 0.7446 - val_loss: 0.5137 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.51354\n",
      "Epoch 156/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5119 - accuracy: 0.7417 - val_loss: 0.5135 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.51354 to 0.51349, saving model to ./model/156-0.5135.hdf5\n",
      "Epoch 157/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5116 - accuracy: 0.7417 - val_loss: 0.5136 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.51349\n",
      "Epoch 158/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5123 - accuracy: 0.7424 - val_loss: 0.5131 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.51349 to 0.51314, saving model to ./model/158-0.5131.hdf5\n",
      "Epoch 159/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5119 - accuracy: 0.7430 - val_loss: 0.5142 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.51314\n",
      "Epoch 160/200\n",
      "3109/3109 [==============================] - 0s 4us/step - loss: 0.5118 - accuracy: 0.7427 - val_loss: 0.5133 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.51314\n",
      "Epoch 161/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5111 - accuracy: 0.7427 - val_loss: 0.5138 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.51314\n",
      "Epoch 162/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5116 - accuracy: 0.7443 - val_loss: 0.5132 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.51314\n",
      "Epoch 163/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5116 - accuracy: 0.7433 - val_loss: 0.5132 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.51314\n",
      "Epoch 164/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5117 - accuracy: 0.7417 - val_loss: 0.5134 - val_accuracy: 0.7449\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.51314\n",
      "Epoch 165/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5110 - accuracy: 0.7417 - val_loss: 0.5131 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.51314 to 0.51310, saving model to ./model/165-0.5131.hdf5\n",
      "Epoch 166/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5110 - accuracy: 0.7424 - val_loss: 0.5133 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.51310\n",
      "Epoch 167/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5109 - accuracy: 0.7446 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.51310 to 0.51264, saving model to ./model/167-0.5126.hdf5\n",
      "Epoch 168/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5109 - accuracy: 0.7417 - val_loss: 0.5131 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.51264\n",
      "Epoch 169/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5110 - accuracy: 0.7433 - val_loss: 0.5130 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.51264\n",
      "Epoch 170/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5113 - accuracy: 0.7420 - val_loss: 0.5130 - val_accuracy: 0.7494\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.51264\n",
      "Epoch 171/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5112 - accuracy: 0.7430 - val_loss: 0.5126 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.51264 to 0.51258, saving model to ./model/171-0.5126.hdf5\n",
      "Epoch 172/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5113 - accuracy: 0.7395 - val_loss: 0.5137 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.51258\n",
      "Epoch 173/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5107 - accuracy: 0.7420 - val_loss: 0.5129 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.51258\n",
      "Epoch 174/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5107 - accuracy: 0.7430 - val_loss: 0.5124 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.51258 to 0.51236, saving model to ./model/174-0.5124.hdf5\n",
      "Epoch 175/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5108 - accuracy: 0.7430 - val_loss: 0.5133 - val_accuracy: 0.7494\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.51236\n",
      "Epoch 176/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5111 - accuracy: 0.7430 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.51236 to 0.51197, saving model to ./model/176-0.5120.hdf5\n",
      "Epoch 177/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5108 - accuracy: 0.7427 - val_loss: 0.5125 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.51197\n",
      "Epoch 178/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5105 - accuracy: 0.7424 - val_loss: 0.5122 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.51197\n",
      "Epoch 179/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5100 - accuracy: 0.7424 - val_loss: 0.5130 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.51197\n",
      "Epoch 180/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5101 - accuracy: 0.7436 - val_loss: 0.5119 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.51197 to 0.51194, saving model to ./model/180-0.5119.hdf5\n",
      "Epoch 181/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5101 - accuracy: 0.7411 - val_loss: 0.5120 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.51194\n",
      "Epoch 182/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5099 - accuracy: 0.7436 - val_loss: 0.5122 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.51194\n",
      "Epoch 183/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5103 - accuracy: 0.7424 - val_loss: 0.5118 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.51194 to 0.51179, saving model to ./model/183-0.5118.hdf5\n",
      "Epoch 184/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5109 - accuracy: 0.7430 - val_loss: 0.5116 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.51179 to 0.51163, saving model to ./model/184-0.5116.hdf5\n",
      "Epoch 185/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5114 - accuracy: 0.7424 - val_loss: 0.5138 - val_accuracy: 0.7502\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.51163\n",
      "Epoch 186/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5103 - accuracy: 0.7440 - val_loss: 0.5119 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.51163\n",
      "Epoch 187/200\n",
      "3109/3109 [==============================] - 0s 6us/step - loss: 0.5099 - accuracy: 0.7427 - val_loss: 0.5126 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.51163\n",
      "Epoch 188/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5097 - accuracy: 0.7440 - val_loss: 0.5118 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.51163\n",
      "Epoch 189/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5098 - accuracy: 0.7443 - val_loss: 0.5116 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.51163 to 0.51159, saving model to ./model/189-0.5116.hdf5\n",
      "Epoch 190/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5093 - accuracy: 0.7427 - val_loss: 0.5117 - val_accuracy: 0.7494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00190: val_loss did not improve from 0.51159\n",
      "Epoch 191/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5095 - accuracy: 0.7427 - val_loss: 0.5120 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.51159\n",
      "Epoch 192/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5093 - accuracy: 0.7430 - val_loss: 0.5123 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.51159\n",
      "Epoch 193/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5095 - accuracy: 0.7436 - val_loss: 0.5117 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.51159\n",
      "Epoch 194/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5096 - accuracy: 0.7414 - val_loss: 0.5122 - val_accuracy: 0.7494\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.51159\n",
      "Epoch 195/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5093 - accuracy: 0.7427 - val_loss: 0.5117 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.51159\n",
      "Epoch 196/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5092 - accuracy: 0.7433 - val_loss: 0.5120 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.51159\n",
      "Epoch 197/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5091 - accuracy: 0.7424 - val_loss: 0.5116 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.51159\n",
      "Epoch 198/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5093 - accuracy: 0.7420 - val_loss: 0.5112 - val_accuracy: 0.7479\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.51159 to 0.51123, saving model to ./model/198-0.5112.hdf5\n",
      "Epoch 199/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5090 - accuracy: 0.7420 - val_loss: 0.5119 - val_accuracy: 0.7464\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.51123\n",
      "Epoch 200/200\n",
      "3109/3109 [==============================] - 0s 5us/step - loss: 0.5090 - accuracy: 0.7411 - val_loss: 0.5114 - val_accuracy: 0.7494\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.51123\n",
      "1333/1333 [==============================] - 0s 9us/step\n",
      "\n",
      " Accuracy: 0.7494\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "# Set the folder for saving the model\n",
    "MODEL_DIR = './model'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "#Save updated model\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss',verbose=1,save_best_only=True)\n",
    "\n",
    "#Stop learning\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=100)\n",
    "\n",
    "#model.fit(X, y, validation_split=0.2, epochs = 10, batch_size=200, verbose=0, callbacks=[checkpointer])\n",
    "#model.fit(X, y, validation_split=0.2, epochs = 120, batch_size=200, verbose=1, \n",
    "#          callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=[X_test,y_test], epochs=200, batch_size=300,\n",
    "                    callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" %  model.evaluate(X_test,y_test)[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set error\n",
    "y_vloss = history.history['val_loss']\n",
    "# Train set error\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "y_acc = history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make the graph\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3, label='Trainset_loss')\n",
    "\n",
    "# Plot \n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70296746, 0.29703254]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[283, 252],\n",
       "       [ 82, 716]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(y_test0, y_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(24.0, 0.5, 'HasDetections')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(y_test0, y_pred)\n",
    "conf_mx\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test0, y_pred)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "hm = sn.heatmap(cmn, annot=True, fmt='.2f')#, x_label='label')\n",
    "hm.axes.set_title(\"MLP\",fontsize=18)\n",
    "hm.set_xlabel('Prediction: HasDetections',fontsize=15)\n",
    "hm.set_ylabel('HasDetections',fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
